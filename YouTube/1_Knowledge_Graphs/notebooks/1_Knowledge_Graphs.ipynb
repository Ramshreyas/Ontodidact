{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Knowledge Graphs\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Ramshreyas/Ontodidact/blob/main/YouTube/1_Knowledge_Graphs/notebooks/1_Knowledge_Graphs.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install llama-index networkx matplotlib pyvis llama-index-graph-stores-neo4j llama-index-embeddings-huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports\n",
    "import os\n",
    "from pprint import pprint\n",
    "import dotenv\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "# Async\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### A toy knowledge graph\n",
    "\n",
    "A knowledge graphs represents **knowledge** in the form of *entities* and the **relationships** between them. Let's use the family tree of House Lannister from Game of Thrones as an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import network visualitzation libraries\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a directed graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.DiGraph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add nodes for each member of the Lannister family - these are our **entities**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "characters = [\"Tywin\", \"Joanna\", \"Cersei\", \"Jaime\", \"Tyrion\", \"Joffrey\", \"Myrcella\", \"Tommen\"]\n",
    "G.add_nodes_from(characters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's add their **relationships**. \n",
    "\n",
    "Here we are only considering parent-child relationships, so this would essentially represent a family tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding relationships\n",
    "relationships = [\n",
    "    (\"Tywin\", \"Cersei\"), (\"Joanna\", \"Cersei\"),\n",
    "    (\"Tywin\", \"Jaime\"), (\"Joanna\", \"Jaime\"),\n",
    "    (\"Tywin\", \"Tyrion\"), (\"Joanna\", \"Tyrion\"),\n",
    "    (\"Cersei\", \"Joffrey\"), (\"Jaime\", \"Joffrey\"),\n",
    "    (\"Cersei\", \"Myrcella\"), (\"Jaime\", \"Myrcella\"),\n",
    "    (\"Cersei\", \"Tommen\"), (\"Jaime\", \"Tommen\")\n",
    "]\n",
    "G.add_edges_from(relationships)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the House Lannister"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding relationships\n",
    "relationships = [\n",
    "    (\"Tywin\", \"Cersei\"), (\"Joanna\", \"Cersei\"),\n",
    "    (\"Tywin\", \"Jaime\"), (\"Joanna\", \"Jaime\"),\n",
    "    (\"Tywin\", \"Tyrion\"), (\"Joanna\", \"Tyrion\"),\n",
    "    (\"Cersei\", \"Joffrey\"), (\"Jaime\", \"Joffrey\"),\n",
    "    (\"Cersei\", \"Myrcella\"), (\"Jaime\", \"Myrcella\"),\n",
    "    (\"Cersei\", \"Tommen\"), (\"Jaime\", \"Tommen\")\n",
    "]\n",
    "G.add_edges_from(relationships)\n",
    "\n",
    "# Manually set positions for a family tree layout\n",
    "pos = {\n",
    "    \"Tywin\": (0.5, 1),\n",
    "    \"Joanna\": (1.5, 1),\n",
    "    \"Cersei\": (0, 0.5),\n",
    "    \"Jaime\": (1, 0.5),\n",
    "    \"Tyrion\": (2, 0.5),\n",
    "    \"Joffrey\": (0, 0),\n",
    "    \"Myrcella\": (1, 0),\n",
    "    \"Tommen\": (2, 0)\n",
    "}\n",
    "\n",
    "# Draw nodes and edges\n",
    "nx.draw(G, pos, with_labels=True, node_color='lightblue', edge_color='gray', node_size=3000, font_size=10, font_color=\"black\")\n",
    "\n",
    "plt.title('Lannister Family Tree')\n",
    "plt.axis('off')  # Turn off the axis\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So this family tree represents a particular piece of knowledge. \n",
    "\n",
    "It contains *explicit* knowledge - that Jaime (illegitimately) fathered Joffrey.\n",
    "\n",
    "It also contains *implicit* knowledge - that Cersei and Jaime are siblings, which is not directly represented as a relationship between the entities - more on this later.\n",
    "\n",
    "In this visualization, entities are represented by nodes or *verteces*, and relationships are represented by the lines or *edges* connecting them.\n",
    "\n",
    "This is a simple knowledge graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### LLMs can extract knowledge graphs directly from text\n",
    "\n",
    "Now I'm sure you'll agree that was a bit tedious. Listing our relationships explicitly and building knowledge graphs can get overwhelming very quickly. \n",
    "\n",
    "The good news is that LLMs and LlamaIndex can help! This is where things get really interesting. \n",
    "\n",
    "Let's load a text description of house Lannister, which we will use as a source to create a knowledge graph without OpenAI and LlamaIndex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "documents = SimpleDirectoryReader(\"./data/\").load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(documents[0].get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct the knowledge graph index for the loaded documents using PropertyGraphIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core.indices.property_graph import SchemaLLMPathExtractor\n",
    "\n",
    "# best practice to use upper-case\n",
    "entities = Literal[\"PERSON\"]\n",
    "relations = Literal[\"CHILD_OF\", 'PARENT_OF', \"SIBLING_OF\", \"SPOUSE_OF\"]\n",
    "\n",
    "# define which entities can have which relations\n",
    "validation_schema = {\n",
    "    \"PERSON\": [\"CHILD_OF\", \"PARENT_OF\", \"SIBLING_OF\", \"SPOUSE_OF\"],\n",
    "}\n",
    "\n",
    "kg_extractor = SchemaLLMPathExtractor(\n",
    "    llm=OpenAI(model=\"gpt-3.5-turbo\", temperature=0.3),\n",
    "    possible_entities=entities,\n",
    "    possible_relations=relations,\n",
    "    kg_validation_schema=validation_schema,\n",
    "    # if false, allows for values outside of the schema\n",
    "    # useful for using the schema as a suggestion\n",
    "    strict=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize a Graph Store and an empty vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.graph_stores.neo4j import Neo4jPGStore\n",
    "\n",
    "graph_store = Neo4jPGStore(\n",
    "    username=\"neo4j\",\n",
    "    password=os.getenv(\"NEO4J_PASSWORD\"),\n",
    "    url=\"bolt://localhost:7687\",\n",
    ")\n",
    "vec_store = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now create a PropertyGraph Index which will generate our knowledge graph automatically from the text!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import PropertyGraphIndex\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "\n",
    "index = PropertyGraphIndex.from_documents(\n",
    "    documents,\n",
    "    kg_extractors=[kg_extractor],\n",
    "    embed_model=HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\"),\n",
    "    property_graph_store=graph_store,\n",
    "    vector_store=vec_store,\n",
    "    show_progress=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Viewing the knowledge graph with Neo4j (is awesome)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Querying the knowledge graph (is deterministic)\n",
    "\n",
    "Now let's create LLM-powered retrievers to query the knowledge graph using natural language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.indices.property_graph import (\n",
    "    LLMSynonymRetriever,\n",
    "    VectorContextRetriever,\n",
    ")\n",
    "\n",
    "\n",
    "llm_synonym = LLMSynonymRetriever(\n",
    "    index.property_graph_store,\n",
    "    llm=OpenAI(model=\"gpt-3.5-turbo\", temperature=0.1),\n",
    "    include_text=False,\n",
    ")\n",
    "\n",
    "vector_context = VectorContextRetriever(\n",
    "    index.property_graph_store,\n",
    "    embed_model=HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\"),\n",
    "    include_text=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = index.as_retriever(\n",
    "    sub_retrievers=[\n",
    "        llm_synonym,\n",
    "        vector_context,\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = retriever.retrieve(\"Who is Tommen's mother?\")\n",
    "\n",
    "for node in nodes:\n",
    "    print(node.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Knowledge Graph query engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = index.as_query_engine(\n",
    "    sub_retrievers=[\n",
    "        llm_synonym,\n",
    "        vector_context,\n",
    "    ],\n",
    "    llm=OpenAI(model=\"gpt-3.5-turbo\", temperature=0.1),\n",
    ")\n",
    "\n",
    "response = query_engine.query(\"Who are Tyrion's siblings?\")\n",
    "\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
